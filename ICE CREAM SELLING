/**
 * Clase que implementa el modelo de Regresion Lineal
 * Utiliza el algoritmo de Gradient Descent para entrenar el modelo
 */
class RegresionLineal {
    // Atributos del modelo
    private double[] weights;                  // Coeficientes de la regresion (w)
    private double bias;                       // Termino independiente (b)
    private boolean ajustado;                  // Indica si el modelo ha sido entrenado
    private double[] mediaEscalador;           // Media de cada caracteristica para normalizacion
    private double[] desviacionEscalador;      // Desviacion estandar para normalizacion
    private double tasaAprendizaje;            // Learning rate para gradient descent
    private int epocas;                        // Numero de iteraciones de entrenamiento
    private double[] historialCosto;           // Almacena el costo en cada epoca
    private int tamanioHistorialCosto;         // Contador del historial
    
    /**
     * Constructor del modelo de regresion lineal
     * @param tasaAprendizaje Velocidad de aprendizaje (alpha)
     * @param epocas Numero de iteraciones de entrenamiento
     */
    public RegresionLineal(double tasaAprendizaje, int epocas) {
        this.weights = null;
        this.bias = 0.0;
        this.ajustado = false;
        this.mediaEscalador = null;
        this.desviacionEscalador = null;
        this.tasaAprendizaje = tasaAprendizaje;
        this.epocas = epocas;
        this.historialCosto = new double[epocas / 100 + 1];
        this.tamanioHistorialCosto = 0;
    }
    
    /**
     * Calcula la media (promedio) de un arreglo
     * @param arreglo Arreglo de numeros
     * @return Valor promedio
     */
    private double media(double[] arreglo) {
        double suma = 0.0;
        for (int i = 0; i < arreglo.length; i++) {
            suma += arreglo[i];
        }
        return suma / arreglo.length;
    }
    
    /**
     * Calcula la desviacion estandar de un arreglo
     * Formula: sqrt(sum((x - mean)^2) / n)
     * @param arreglo Arreglo de numeros
     * @return Desviacion estandar
     */
    private double desviacionEstandar(double[] arreglo) {
        double valorMedia = media(arreglo);
        double sumaDiferenciasCuadrado = 0.0;
        for (int i = 0; i < arreglo.length; i++) {
            double diferencia = arreglo[i] - valorMedia;
            sumaDiferenciasCuadrado += diferencia * diferencia;
        }
        return Math.sqrt(sumaDiferenciasCuadrado / arreglo.length);
    }
    
    /**
     * Extrae una columna especifica de una matriz
     * @param matriz Matriz de datos
     * @param indiceColumna Indice de la columna a extraer
     * @return Arreglo con los valores de la columna
     */
    private double[] obtenerColumna(double[][] matriz, int indiceColumna) {
        double[] columna = new double[matriz.length];
        for (int i = 0; i < matriz.length; i++) {
            columna[i] = matriz[i][indiceColumna];
        }
        return columna;
    }
    
    /**
     * Normaliza los datos usando StandardScaler (z-score)
     * Formula: (x - media) / desviacion_estandar
     * Esto ayuda a que el gradient descent converja mas rapido
     * 
     * @param X Matriz de caracteristicas
     * @param ajustarEscalador Si es true, calcula media y desviacion; si es false, usa valores previos
     * @return Matriz normalizada
     */
    public double[][] data_scaling(double[][] X, boolean ajustarEscalador) {
        int numeroMuestras = X.length;
        int numeroCaracteristicas = X[0].length;
        
        // Si es la primera vez, calcular media y desviacion de cada caracteristica
        if (ajustarEscalador) {
            mediaEscalador = new double[numeroCaracteristicas];
            desviacionEscalador = new double[numeroCaracteristicas];
            
            for (int j = 0; j < numeroCaracteristicas; j++) {
                double[] columna = obtenerColumna(X, j);
                mediaEscalador[j] = media(columna);
                desviacionEscalador[j] = desviacionEstandar(columna);
                // Evitar division por cero
                if (desviacionEscalador[j] == 0) desviacionEscalador[j] = 1.0;
            }
        }
        
        // Validar que el escalador este configurado
        if (mediaEscalador == null || desviacionEscalador == null) {
            throw new RuntimeException("Escalador no ajustado");
        }
        
        // Aplicar normalizacion a cada valor
        double[][] matrizEscalada = new double[numeroMuestras][numeroCaracteristicas];
        for (int i = 0; i < numeroMuestras; i++) {
            for (int j = 0; j < numeroCaracteristicas; j++) {
                matrizEscalada[i][j] = (X[i][j] - mediaEscalador[j]) / desviacionEscalador[j];
            }
        }
        return matrizEscalada;
    }
    
    /**
     * Entrena el modelo usando Gradient Descent
     * Algoritmo:
     * 1. Calcular predicciones: y_pred = X * w + b
     * 2. Calcular error: error = y_pred - y_real
     * 3. Calcular gradientes: dw = (X^T * error) / m, db = sum(error) / m
     * 4. Actualizar parametros: w = w - alpha * dw, b = b - alpha * db
     * 5. Repetir por numero de epocas
     * 
     * @param XEntrenamiento Matriz de caracteristicas de entrenamiento
     * @param yEntrenamiento Vector de valores objetivo de entrenamiento
     * @param usarEscalado Si normalizar los datos o no
     */
    public void fit(double[][] XEntrenamiento, double[] yEntrenamiento, boolean usarEscalado) {
        double[][] X = XEntrenamiento;
        double[] y = yEntrenamiento;
        
        // Validar dimensiones
        if (X.length != y.length) {
            throw new RuntimeException("X e y deben tener el mismo numero de muestras");
        }
        
        // Normalizar datos si se solicita
        if (usarEscalado) {
            X = data_scaling(X, true);
        }
        
        // Inicializar parametros
        int m = X.length;                  // Numero de muestras
        int n = X[0].length;               // Numero de caracteristicas
        weights = new double[n];           // Inicializar pesos en 0
        bias = 0.0;                        // Inicializar sesgo en 0
        tamanioHistorialCosto = 0;
        
        // Gradient Descent - Bucle principal de entrenamiento
        for (int epoca = 0; epoca < epocas; epoca++) {
            // Paso 1: Forward propagation - Calcular predicciones
            // y_pred = X * w + b
            double[] predicciones = new double[m];
            for (int i = 0; i < m; i++) {
                predicciones[i] = bias;
                for (int j = 0; j < n; j++) {
                    predicciones[i] += X[i][j] * weights[j];
                }
            }
            
            // Paso 2: Calcular errores
            // error = y_pred - y_real
            double[] errores = new double[m];
            for (int i = 0; i < m; i++) {
                errores[i] = predicciones[i] - y[i];
            }
            
            // Paso 3: Calcular gradientes para los pesos
            // dw = (1/m) * X^T * error
            double[] dw = new double[n];
            for (int j = 0; j < n; j++) {
                double suma = 0.0;
                for (int i = 0; i < m; i++) {
                    suma += X[i][j] * errores[i];
                }
                dw[j] = suma / m;
            }
            
            // Paso 4: Calcular gradiente para el sesgo
            // db = (1/m) * sum(error)
            double db = 0.0;
            for (int i = 0; i < m; i++) {
                db += errores[i];
            }
            db = db / m;
            
            // Paso 5: Actualizar parametros
            // w = w - alpha * dw
            // b = b - alpha * db
            for (int j = 0; j < n; j++) {
                weights[j] -= tasaAprendizaje * dw[j];
            }
            bias -= tasaAprendizaje * db;
            
            // Guardar costo cada 100 epocas para monitoreo
            if (epoca % 100 == 0) {
                // Calcular funcion de costo: MSE / 2
                double costo = 0.0;
                for (int i = 0; i < m; i++) {
                    costo += errores[i] * errores[i];
                }
                costo = costo / (2 * m);
                historialCosto[tamanioHistorialCosto++] = costo;
                
                // Imprimir progreso cada 1000 epocas
                if (epoca % 1000 == 0) {
                    System.out.println("Epoca " + epoca + "/" + epocas + " - Costo: " + formatearDecimal(costo, 4));
                }
            }
        }
        
        ajustado = true;
        System.out.println("\nEntrenamiento completado!");
        System.out.println("Costo final: " + formatearDecimal(historialCosto[tamanioHistorialCosto - 1], 4));
    }
    
    /**
     * Realiza predicciones usando el modelo entrenado
     * Formula: y_pred = X * w + b
     * 
     * @param XPrueba Matriz de caracteristicas para predecir
     * @return Arreglo con las predicciones
     */
    public double[] predict(double[][] XPrueba) {
        if (!ajustado) {
            throw new RuntimeException("El modelo debe ser ajustado primero");
        }
        
        // Normalizar datos de prueba usando los parametros del entrenamiento
        double[][] X = XPrueba;
        if (mediaEscalador != null) {
            X = data_scaling(X, false);
        }
        
        // Calcular predicciones
        double[] predicciones = new double[X.length];
        for (int i = 0; i < X.length; i++) {
            predicciones[i] = bias;
            for (int j = 0; j < weights.length; j++) {
                predicciones[i] += X[i][j] * weights[j];
            }
        }
        return predicciones;
    }
    
    /**
     * Calcula el coeficiente de determinacion R^2
     * R^2 = 1 - (SS_res / SS_tot)
     * SS_res = sum((y_real - y_pred)^2)
     * SS_tot = sum((y_real - y_mean)^2)
     * 
     * R^2 cercano a 1 = buen ajuste
     * R^2 cercano a 0 = ajuste pobre
     * 
     * @param XPrueba Matriz de caracteristicas de prueba
     * @param yPrueba Vector de valores reales de prueba
     * @return Valor de R^2
     */
    public double score(double[][] XPrueba, double[] yPrueba) {
        double[] predicciones = predict(XPrueba);
        
        // Calcular suma de cuadrados de residuos (SS_res)
        double ssRes = 0.0;
        for (int i = 0; i < yPrueba.length; i++) {
            double residuo = yPrueba[i] - predicciones[i];
            ssRes += residuo * residuo;
        }
        
        // Calcular suma total de cuadrados (SS_tot)
        double yMedia = media(yPrueba);
        double ssTot = 0.0;
        for (int i = 0; i < yPrueba.length; i++) {
            double diferencia = yPrueba[i] - yMedia;
            ssTot += diferencia * diferencia;
        }
        
        // Calcular R^2
        return 1.0 - (ssRes / ssTot);
    }
    
    /**
     * Obtiene una copia de los pesos del modelo
     * @return Arreglo con los pesos
     */
    public double[] getWeights() {
        if (!ajustado) throw new RuntimeException("Modelo no ajustado");
        double[] copia = new double[weights.length];
        for (int i = 0; i < weights.length; i++) {
            copia[i] = weights[i];
        }
        return copia;
    }
    
    /**
     * Obtiene el sesgo del modelo
     * @return Valor del sesgo
     */
    public double getBias() {
        if (!ajustado) throw new RuntimeException("Modelo no ajustado");
        return bias;
    }
    
    /**
     * Formatea un numero decimal con precision especifica
     * @param valor Numero a formatear
     * @param decimales Numero de decimales
     * @return Cadena formateada
     */
    private String formatearDecimal(double valor, int decimales) {
        long multiplicador = 1;
        for (int i = 0; i < decimales; i++) multiplicador *= 10;
        long redondeado = (long)(valor * multiplicador + 0.5);
        long parteEntera = redondeado / multiplicador;
        long parteDecimal = redondeado % multiplicador;
        String cadenaDecimal = "" + parteDecimal;
        while (cadenaDecimal.length() < decimales) cadenaDecimal = "0" + cadenaDecimal;
        return parteEntera + "." + cadenaDecimal;
    }
}

/**
 * Clase auxiliar para almacenar el resultado de la division
 * de datos en conjuntos de entrenamiento y prueba
 */
class DivisionEntrenamientoPrueba {
    double[][] XEntrenamiento;
    double[][] XPrueba;
    double[] yEntrenamiento;
    double[] yPrueba;
}

/**
 * Generador de numeros pseudo-aleatorios simple
 * Usa el algoritmo Linear Congruential Generator (LCG)
 */
class AleatorioSimple {
    private long semilla;
    
    public AleatorioSimple(long semilla) {
        this.semilla = semilla;
    }
    
    /**
     * Genera el siguiente numero aleatorio
     * @param n Limite superior (exclusivo)
     * @return Numero aleatorio entre 0 y n-1
     */
    public int siguienteEntero(int n) {
        semilla = (semilla * 9301 + 49297) % 233280;
        return (int)((semilla / 233280.0) * n);
    }
}

/**
 * Clase principal que ejecuta el analisis de regresion
 * para predecir ventas de helado basandose en la temperatura
 */
public class Main {
    
    /**
     * Repite una cadena un numero determinado de veces
     * @param cadena Cadena a repetir
     * @param veces Numero de repeticiones
     * @return Cadena repetida
     */
    private static String repetir(String cadena, int veces) {
        String resultado = "";
        for (int i = 0; i < veces; i++) resultado += cadena;
        return resultado;
    }
    
    /**
     * Formatea un numero decimal
     * @param valor Numero a formatear
     * @param decimales Numero de decimales
     * @return Cadena formateada
     */
    private static String formatearDecimal(double valor, int decimales) {
        long multiplicador = 1;
        for (int i = 0; i < decimales; i++) multiplicador *= 10;
        long redondeado = (long)(valor * multiplicador + 0.5);
        long parteEntera = redondeado / multiplicador;
        long parteDecimal = redondeado % multiplicador;
        String cadenaDecimal = "" + parteDecimal;
        while (cadenaDecimal.length() < decimales) cadenaDecimal = "0" + cadenaDecimal;
        return parteEntera + "." + cadenaDecimal;
    }
    
    /**
     * Divide los datos en conjuntos de entrenamiento y prueba
     * Implementa shuffle aleatorio para evitar sesgos
     * 
     * @param X Caracteristicas
     * @param y Valores objetivo
     * @param tamanoPrueba Proporcion de datos para prueba (0.0 a 1.0)
     * @param semilla Semilla para reproducibilidad
     * @return Objeto con los datos divididos
     */
    private static DivisionEntrenamientoPrueba dividirEntrenamientoPrueba(double[] X, double[] y, double tamanoPrueba, long semilla) {
        AleatorioSimple aleatorio = new AleatorioSimple(semilla);
        int n = X.length;
        
        // Crear arreglo de indices
        int[] indices = new int[n];
        for (int i = 0; i < n; i++) indices[i] = i;
        
        // Algoritmo de Fisher-Yates para mezclar indices
        for (int i = n - 1; i > 0; i--) {
            int j = aleatorio.siguienteEntero(i + 1);
            int temp = indices[i];
            indices[i] = indices[j];
            indices[j] = temp;
        }
        
        // Calcular tamanos de conjuntos
        int muestrasPrueba = (int) (n * tamanoPrueba);
        int muestrasEntrenamiento = n - muestrasPrueba;
        
        // Crear estructuras de datos
        DivisionEntrenamientoPrueba resultado = new DivisionEntrenamientoPrueba();
        resultado.XEntrenamiento = new double[muestrasEntrenamiento][1];
        resultado.XPrueba = new double[muestrasPrueba][1];
        resultado.yEntrenamiento = new double[muestrasEntrenamiento];
        resultado.yPrueba = new double[muestrasPrueba];
        
        // Llenar conjunto de prueba
        for (int i = 0; i < muestrasPrueba; i++) {
            resultado.XPrueba[i][0] = X[indices[i]];
            resultado.yPrueba[i] = y[indices[i]];
        }
        
        // Llenar conjunto de entrenamiento
        for (int i = 0; i < muestrasEntrenamiento; i++) {
            resultado.XEntrenamiento[i][0] = X[indices[muestrasPrueba + i]];
            resultado.yEntrenamiento[i] = y[indices[muestrasPrueba + i]];
        }
        
        return resultado;
    }
    
    /**
     * Convierte un arreglo de doubles a cadena formateada
     * @param arreglo Arreglo a convertir
     * @return Cadena formateada como [a, b, c]
     */
    private static String arregloACadena(double[] arreglo) {
        String resultado = "[";
        for (int i = 0; i < arreglo.length; i++) {
            resultado += formatearDecimal(arreglo[i], 4);
            if (i < arreglo.length - 1) resultado += ", ";
        }
        resultado += "]";
        return resultado;
    }
    
    /**
     * Metodo principal - Ejecuta el analisis de regresion completo
     */
    public static void main(String[] args) {
        // Encabezado
        System.out.println(repetir("=", 70));
        System.out.println("REGRESION LINEAL SIMPLE - VENTAS DE HELADO");
        System.out.println("Implementacion Java POO");
        System.out.println(repetir("=", 70));
        System.out.println();
        
        // Datos del dataset: temperatura ambiente (variable independiente)
        double[] temperatura = {
            -4.662262677220208, -4.316559446725467, -4.213984764590729, -3.9496610890515707,
            -3.578553716228682, -3.455711698065576, -3.1084401208909964, -3.0813033243034563,
            -2.672460827006454, -2.652286792936049, -2.6514980333001315, -2.288263998488389,
            -2.111869690297304, -1.8189376094349368, -1.6603477296372017, -1.3263789834948425,
            -1.1731232680778254, -0.773330043103446, -0.6737528018380356, -0.5853400736278272,
            -0.574942416132019, -0.2583551779306967, -0.20733127855904146, 0.030226455060361283,
            0.2641351407279732, 0.33881947587413474, 0.6887809945104411, 0.7376433537095569,
            0.8697195532965997, 1.0203916844906384, 1.0228983664943383, 1.4014094966936868,
            1.5272552653024623, 1.6011471882124736, 1.8505421453765086, 2.0424717532622066,
            2.1564569652569755, 2.256765488423142, 2.43935346027903, 2.522766116086672,
            2.784835641871991, 2.890855662346195, 3.1493838195569163, 3.21653765831486,
            3.613098026451943, 3.699820346621779, 4.133048881032591, 4.5967329596939175,
            4.899032068507582
        };
        
        // Datos del dataset: ventas de helado (variable dependiente)
        double[] ventas = {
            41.84298632027783, 34.661119537360234, 39.38300087682567, 37.53984488250128,
            32.28453118789761, 30.00113847641735, 22.635401277012628, 25.36502221208036,
            19.226970048254086, 20.27967917842273, 13.275828499002512, 18.123991212726547,
            11.218294472789265, 10.012867848328882, 12.615181154152336, 10.957731335561812,
            6.689122639625872, 9.392968661109095, 5.210162615266291, 5.162054328795523,
            3.7464717281796815, 5.004503430174844, 2.0662962143791037, 1.4399828854686136,
            1.2982943989716058, 3.8945950828143883, 12.615181154152336, 4.857987831429447,
            0.7905498969196765, 2.3144819638947286, 4.631326893695649, 7.355863819331437,
            9.125913378825985, 7.533331949009965, 4.863569516967947, 4.195419729494037,
            13.177758551451827, 12.387119370326267, 10.294331821916405, 12.522819867847933,
            25.142082089691758, 22.29896669169063, 17.72726815782277, 27.70022399015358,
            28.907181893959787, 17.839691327098955, 27.700245831966394, 32.18451423430885,
            40.48044959902595
        };
        
        // Paso 1: Cargar datos
        System.out.println("Cargando datos...");
        System.out.println("   Forma del conjunto de datos: " + temperatura.length + " muestras");
        System.out.println();
        
        // Paso 2: Dividir datos en entrenamiento (80%) y prueba (20%)
        System.out.println("Dividiendo datos (80% entrenamiento, 20% prueba)...");
        DivisionEntrenamientoPrueba division = dividirEntrenamientoPrueba(temperatura, ventas, 0.2, 42);
        System.out.println("   Conjunto de entrenamiento: " + division.XEntrenamiento.length + " muestras");
        System.out.println("   Conjunto de prueba: " + division.XPrueba.length + " muestras");
        System.out.println();
        
        // Paso 3: Crear modelo de regresion lineal
        // Parametros: learning_rate=0.1, epochs=20000
        System.out.println("Creando modelo de Regresion Lineal...");
        RegresionLineal mlr = new RegresionLineal(0.1, 20000);
        System.out.println();
        
        // Paso 4: Entrenar el modelo
        System.out.println("Entrenando modelo...");
        mlr.fit(division.XEntrenamiento, division.yEntrenamiento, true);
        System.out.println();
        
        // Paso 5: Mostrar parametros aprendidos
        System.out.println(repetir("=", 70));
        System.out.println("PARAMETROS DEL MODELO");
        System.out.println(repetir("=", 70));
        System.out.println("weights: " + arregloACadena(mlr.getWeights()));
        System.out.println("bias: " + mlr.getBias());
        System.out.println();
        
        // Paso 6: Realizar predicciones
        System.out.println(repetir("=", 70));
        System.out.println("PREDICCIONES");
        System.out.println(repetir("=", 70));
        double[] yPredicha = mlr.predict(division.XPrueba);
        
        // Mostrar algunas predicciones de ejemplo
        System.out.println("\nPredicciones de muestra (primeras 5):");
        int numeroMostrar = division.XPrueba.length < 5 ? division.XPrueba.length : 5;
        
        for (int i = 0; i < numeroMostrar; i++) {
            double temp = division.XPrueba[i][0];
            double real = division.yPrueba[i];
            double prediccion = yPredicha[i];
            System.out.println("   Temperatura: " + formatearDecimal(temp, 2) + 
                             " grados C | Real: " + formatearDecimal(real, 2) + 
                             " | Prediccion: " + formatearDecimal(prediccion, 2));
        }
        System.out.println();
        
        // Paso 7: Evaluar el modelo
        System.out.println(repetir("=", 70));
        System.out.println("EVALUACION DEL MODELO");
        System.out.println(repetir("=", 70));
        double puntuacionR2 = mlr.score(division.XPrueba, division.yPrueba);
        System.out.println("score (R cuadrado): " + formatearDecimal(puntuacionR2, 4));
        System.out.println();
        
        // Paso 8: Interpretar resultados
        System.out.println(repetir("=", 70));
        System.out.println("INTERPRETACION");
        System.out.println(repetir("=", 70));
        if (puntuacionR2 > 0.8) {
            System.out.println("Ajuste excelente!");
        } else if (puntuacionR2 > 0.6) {
            System.out.println("Buen ajuste.");
        } else if (puntuacionR2 > 0) {
            System.out.println("Ajuste moderado.");
        } else {
            System.out.println("Ajuste pobre.");
        }
        System.out.println();
        
        // Pie de pagina
        System.out.println(repetir("=", 70));
        System.out.println("ANALISIS COMPLETO");
        System.out.println(repetir("=", 70));
    }
}
